{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### LIN 353C: Introduction to Computational Linguistics,  Fall 2022, Erk\n",
    "\n",
    "# Homework 6:  Part-of-speech tagging\n",
    "\n",
    "## Due: Wednesday November 2, end of day\n",
    "\n",
    "## Your name: Eloragh Espie\n",
    "## Your EID: eae2273\n",
    "\n",
    "This homework comes with the following files:\n",
    "\n",
    "* Introcl_homework_6.ipynb: this notebook, which has the homework problems. **Please put your answers into this same notebook.**\n",
    "\n",
    "\n",
    "Please record all your answers in the appropriate place in this notebook, and **do not forget to put your name and EID at the top of this notebook**.\n",
    "\n",
    "For the part of the homework that requires you to write Python code,\n",
    "we need to see the code.\n",
    "You can omit statements that\n",
    "produced an error or that did not form part of the eventual solution,\n",
    "but please include all the Python code that formed part of your\n",
    "solution. \n",
    "\n",
    "Please use comments to explain what your code does. Any code that seems complicated to you, or goes on for more than 2 lines, can probably use a comment. Just practice commenting more than you think the code needs. As you will see once you pull out an old piece of code you wrote and try to figure out what you were doing, code always needs more comments than you think.\n",
    "\n",
    "### Important note: Please hit the fast-forward button on this notebook, and confirm \"Restart and Run all cells\", so the code included in this notebook will be executed on your machine. However, there is one command below (loading a gensim space) that may take a while, please plan for that. \n",
    "\n",
    "\n",
    "**If any of these instructions do not make sense to you, please get in\n",
    " touch with the instructor right away.**\n",
    "\n",
    "\n",
    "A perfect solution to this homework will be worth *100* points. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1: Ambiguity resolved by part-of-speech tags. (24 points)\n",
    "\n",
    "Scour the web for 3 examples of newspaper headlines with odd alterna- tive interpretations, such as *British Left Waffles on Falkland Islands*, or *Iranian TV shows downed US drone*. Do not get them from sites that specialize in such headlines -- instead, get them from recent head-lines from actual news sites, like the BBC (Google news should be quite useful here as well). These cases are much more frequent than you would think; you will easily find enough examples.\n",
    "For each headline,\n",
    "\n",
    "* sketch the different readings that you perceive,\n",
    "* manually tag the headline, and\n",
    "* state whether knowledge of the part-of-speech tags removes the ambiguity.\n",
    "\n",
    "Use the following as your basic set of tags:\n",
    "\n",
    "* *V* verbs (sleeps, gave)\n",
    "* *DT* determiners (the, a)\n",
    "* *NN* common nouns (the dog)\n",
    "* *NNP* proper nouns (Europe, University of Texas at Austin) \n",
    "* *JJ* adjectives (smart, lucky)\n",
    "* *RB* adverbs (quietly, yesterday)\n",
    "* *P* preposition (of, on)\n",
    "* *CC* coordinating conjunction (and, or, but)\n",
    "\n",
    "You don’t need to worry about getting all your tags absolutely perfect. Just do what seems most sensible. In case you want to have more fine-grained tags, feel free to consult the Penn Treebank tagging guidelines: https://repository.upenn.edu/cis_reports/570/\n",
    "\n",
    "Tag each of the headlines using the word/tag format:\n",
    "\n",
    "    British/JJ Left/NN Waffles/V on/P Falkland/NNP Islands/NNP\n",
    "\n",
    "These kind of headlines are called crash blossoms. For the reason, see http://languagelog.ldc.upenn.edu/nll/?p=1693\n",
    "\n",
    "For an entertaining list of crash blossoms, see https://languagelog.ldc.upenn.edu/nll/?cat=118 (But do not use these for your homework.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*space for your text answer here*\n",
    "\n",
    "### Crash Blossoms\n",
    "\n",
    "a. \"Knife crime: St John Ambulance to teach teens to help stab victims.\"\n",
    "\n",
    "b. \"McDonald’s Fries the Holy Grail for Potato Farmers.\"\n",
    "\n",
    "c. \"Israel Ducks on Human Rights.\"\n",
    "\n",
    "### Interpretations\n",
    "\n",
    "a.\n",
    "\n",
    "In response to knife crime, an ambulance team/company is educating students on how to assist stab victims.\n",
    "\n",
    "    Knife/NN Crime/NN St John/NNP Ambulance/NN to/TO teach/V teens/NN to/TO help/V stab/JJ victims/NN.\n",
    "    \n",
    "In response to knife crime, an ambulance team/company is educating students on how to assist in the stabbing of the victims.\n",
    "\n",
    "    Knife/NN Crime/NN St John/NNP Ambulance/NN to/TO teach/V teens/NN to/TO help/V stab/V victims/NN.\n",
    "\n",
    "The knowledge of the POS tags definitely removes the ambiguity. It's clear that the first interpretation is what the writer intended to express. \n",
    "\n",
    "b.\n",
    "\n",
    "McDonald's Fries are the highest achievement possible for potato farmers in regards to how their potatoes are used.\n",
    "\n",
    "    McDonald's/NN Fries/NN the/DT Holy Grail/NNP for/P Potato/JJ Farmers/NN.\n",
    "\n",
    "McDonalds is frying the object considered a \"Holy Grail\" by potato farmers.\n",
    "\n",
    "    McDonald's/NN Fries/V the/DT Holy Grail/NNP for/P Potato/JJ Farmers/NN.\n",
    "\n",
    "The POS tags also remove the ambiguity here. I find both interpretations funny though. I can't imagine that most potato farmers care about the end use of their crop, McDonald's fries or not.\n",
    "\n",
    "c.\n",
    "\n",
    "Israel is avoidant in providing a response on human rights issues.\n",
    "\n",
    "    Israel/NNP ducks/V on/P human rights/NN.\n",
    "\n",
    "Reporters are interviewing Israeli ducks in regards to their thoughts on human rights.\n",
    "\n",
    "    Israel/NNP ducks/NN on/P human rights/NN.\n",
    "\n",
    "Yes, the POS tags here remove the ambiguity. However, the word \"ducks\" was a poor choice, I don't think most people think of the verb on first glance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2: Thinking about part-of-speech tagging (30 pts.)\n",
    "\n",
    "## Part a\n",
    "\n",
    "Among the different types of part-of-speech taggers in chapter 5 of the NLTK book was the Default Tagger, which tags all words with the same part of speech. Name two reasons why it make sense to have such a tagger."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*space for your text answer here*\n",
    "\n",
    "1. Default taggers establish a baseline for future accuracy improvements. By assigning every word to the same POS tag, we know that this tagger is not going to perform well. The accuracy it provides allows future iterations of the POS tagger to be judged against an intentionally wrong system to measure improvement.\n",
    "\n",
    "2. Default taggers are also very readable and easy to understand. As someone tries to write more and more complex POS tagging systems, a default tagger can be a good place to return for consistency and understanding of the data. It's the opposite of a blackbox."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part b\n",
    "\n",
    "The Lookup Tagger in chapter 5 of the NLTK book first uses tagged data to determine the most frequent tag for each of the n most frequent words in the corpus. It then remembers this most frequent tag for each of these words, and always assigns that.\n",
    "We added a \"backoff\" such that for words that are not in its list of remembered words with tags, it always guesses “noun”.\n",
    "\n",
    "Chapter 5 of the NLTK book shows a graph (Figure 4.2) that charts the number of most frequent words used against the accuracy that the tagger achieves.\n",
    "If you use the 100 most frequent words in the news section of the Brown corpus, then the tagger already reaches an accuracy of 46% on that corpus. Why is it that this simple tagger gets such a relatively high value?\n",
    "If you keep adding more and more words with their most frequent tags to this tagger, the model improves up until about 93% accuracy. Why does it not reach 100%?\n",
    "And why do you think it is that in the beginning, adding more words makes the model improve fast, but after a while, the performance levels off?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*space for your text answer here*\n",
    "\n",
    "- This simple tagger gets a relatively high accuracy value because it's identifying the most used words and tagging them with the most likely tag available for them. By doing this, a large chunk of words in the corpus will be tagged with a POS and a decent percentage within that chunk will be tagged with the correct POS tag, quickly driving up the accuracy rate.\n",
    "\n",
    "- The model never reaches 100% accuracy because it doesn't take context into account. By mass tagging words only based on the likeliest part of speech, you're always going to mistag some words.\n",
    "\n",
    "- By tagging the 100 most frequent words, the accuracy spikes because those words make up a good portion of the corpus. The more words you add, the less and less frequent the words are. By the time you tag the 1000 - 2000 most frequent words in the corpus on this model, the gains level off probably due to the lack of representation within the corpus. The \"frequent\" words are not frequent enough to make a difference in the accuracy number."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part c\n",
    "\n",
    "If you evaluate this Lookup Tagger using all the words in the Brown news section, it achieves an accuracy of 93%. If you evaluate the same tagger (trained on Brown news) on the fiction part of the Brown corpus, you get 80% accuracy. Those are quite different numbers. Which of those two numbers should you trust more? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*space for your text answer here *\n",
    "\n",
    "You should trust the accuracy when you test it on the fiction section.\n",
    "\n",
    "Taggers need to have flexibility and reliability across genres, subjects, concepts, etc. That's why it's important to test taggers on a variety of corpuses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3: Using a Hidden Markov Model to determine the probability of a tag sequence (40 pts.) \n",
    "\n",
    "\n",
    "The English Wikipedia has this to say about garden path sentences:\n",
    "\n",
    ">A garden path sentence, such as “The old man the boat” (meaning “Old people are the crew of the boat”), is a grammatically correct sentence that starts in such a way that a reader’s most likely interpretation will be incorrect; the reader is lured into a parse that turns out to be a dead end or yields a clearly unintended meaning. “Garden path” refers to the saying “to be led down [or up] the garden path”, meaning to be deceived, tricked, or seduced.\n",
    "\n",
    "Another well-known garden path sentence is\n",
    "\n",
    "> The complex houses married and single soldiers and their families\n",
    "\n",
    "For this problem, you will do part-of-speech tagging for a simplified version of this sentence: \n",
    "\n",
    "> the complex houses students\n",
    "\n",
    "Here are the transition probabilities:\n",
    "\n",
    "* **START**: P(DT|START)=0.14 \n",
    "* **DT**: P(JJ|DT) = 0.23, P(NN|DT) = 0.61\n",
    "* **JJ**: P(NN|JJ) = 0.64, P(VB|JJ) = 0.01\n",
    "* **NN**: P(NN|NN) = 0.1,  P(V B|NN) = 0.06, P(END|NN) = 0.003 \n",
    "* **VB**: P(NN|VB)=0.11\n",
    "\n",
    "Here are emission probabilities. Assume all other emission probabilities are zero:\n",
    "\n",
    "* **the:** P(the|DT)=0.63\n",
    "* **complex:** P(complex|JJ) = 0.0008, P(complex|NN) = 0.0001\n",
    "* **houses:** P(houses|NN) = 0.0003, P(houses|V B) = 0.00003 \n",
    "* **students:** P(students|NN) = 0.0009\n",
    "\n",
    "What is the probability of the following tag sequence? \n",
    "\n",
    "> START DT NN VB NN\n",
    "\n",
    "Please do this \"by hand\", and show your work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*space for your text answer here*\n",
    "\n",
    "The 0th viterbi number is the probability that START will occur, which is always 1.\n",
    "\n",
    "- v0 = P(START) = 1\n",
    "\n",
    "The 1st viterbi number is the probability that v0 will occur and P(DT | START) and P(the | DT) . \n",
    "\n",
    "- v1 = (v0 * P(DT | START)) * P(the | DT) = 1 * 0.14 * 0.63 = 0.0882\n",
    "\n",
    "The 2nd viterbi number is the probability that v1 will occur and P(NN | DT) and P(complex | NN).\n",
    "\n",
    "- v2 = (v1 * P(NN | DT)) * P(complex | NN) = 0.0882 * 0.61 * 0.0001 = 5.380210 * 10<sup>−6</sup>\n",
    "\n",
    "The 3rd viterbi number is the probability that v2 will occur and P(VB | NN) and P(houses | VB).\n",
    "\n",
    "- v3 = (v2 * P(VB | NN)) * P(houses | VB) = (5.3802*10<sup>−6</sup> * 0.06) * 0.00003 = 9.68436 * 10<sup>-12</sup>\n",
    "\n",
    "The 4th viterbi number is the probability that v3 wil occur and P(NN | VB) and P(students | NN).\n",
    "\n",
    "- v4 = (v3 * P(NN | VB)) * P(students | NN) = (9.68436 * 10<sup>-12</sup> * 0.11) * 0.0009 = 9.5875164 * 10<sup>−16</sup>\n",
    "\n",
    "**P(START DT NN VB NN | the complex houses students) = 9.5875164 * 10<sup>−16</sup>**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 4: Viterbi (6 pts.)\n",
    "\n",
    "The Viterbi algorithm is used to determine the best tag sequence for a given word sequence. It is a dynamic programming approach, meaning that it stores intermediate results instead of recomputing them, in order to bring the runtime down a lot. \n",
    "\n",
    "The intermediate results that are being stored in the Viterbi algorithm are probabilities $v_t(j)$, meaning the probability of the most likely path ending in state (POS tag) $j$ in step $t$ (at the $t$-th word). \n",
    "\n",
    "The Viterbi probability $v_t(j)$ of the most likely path ending in $j$ and emitting word $o_t$ is\n",
    "\n",
    "$v_t(j) = max_i v_{t-1}(i) a_{ij} b_j(o_t)$\n",
    "\n",
    "So for each tag $i$, we look at the probability of the most likely path that ends at $i$ at step $t-1$, multiply it with the probability of transitioning from $i$ to $j$ (that is $a_{ij}$) and with the probability of emitting the $t$-th observation from state (POS tag) $j$ (this is $b_j$). We compare all these probabilities, and take the maximum. This, then, is the probability of the likeliest path ending at $j$ at step $t$. \n",
    "\n",
    "We back to the sentence \"the complex houses students\" from the previous sentence. \n",
    "\n",
    "Say we have this for observation 2, \"complex\":\n",
    "* $v_2(JJ) = 2e-4$\n",
    "* $v_2(NN) = 5.5e-6$\n",
    "* and $v_2$ is zero for all other tags. \n",
    "\n",
    "Then what is $v_3(VB)$, the probability of the likeliest path that ends at tag VB in step 3, that is, that tags \"houses\" with VB? So here $t=3$, $j = VB$, and you have to compare tags $i$ that are either JJ or NN. \n",
    "\n",
    "Do this by hand, and show your work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*space for your text answer here*\n",
    "\n",
    "Two possible tags for \"complex\".\n",
    "\n",
    "- $v_2(JJ) = 2e-4$\n",
    "\n",
    "- $v_2(NN) = 5.5e-6$\n",
    "\n",
    "Evaluate the transition between JJ &rarr; VB and NN &rarr; VB.\n",
    "\n",
    "- $v_2(JJ) * P(VB | JJ) = 2e-4 * 0.01 = 2.0000000000000003e-06$\n",
    "\n",
    "- $v_2(NN) * P(VB |NN) = 5.5e-6 * 0.006 = 3.3e-08$\n",
    "\n",
    "Find the maximum likelihood between the two probabilities and multiply it by the probability that VB emits \"houses\".\n",
    "\n",
    "- $v_3(VB) = max(2.0000000000000003e-06, 3.3e-08) * P(houses | VB) = 2.0000000000000003e-06 * 0.00003$\n",
    "\n",
    "The likeliest path that ends at tag VB and tags \"houses\" as VB is found by tagging \"complex\" as JJ.\n",
    "\n",
    "- $v_3(VB) = 6.000000000000001e-11$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
