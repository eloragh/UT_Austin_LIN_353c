{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27bd345e",
   "metadata": {},
   "source": [
    "# How to train simple bigram language models in practice\n",
    "\n",
    "This notebook demonstrates word counting and bigram language models.\n",
    "\n",
    "## The \"Sam corpus\"\n",
    "\n",
    "Our first example uses the Green Eggs and Ham poem as a \"corpus\" from which we train a language model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5aa7d69b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus as a list of sentences: ['I am Sam.', 'Sam I am.', 'I do not like green eggs and ham.']\n"
     ]
    }
   ],
   "source": [
    "# we import the natural language toolkit\n",
    "import nltk\n",
    "\n",
    "\n",
    "# Here is our corpus, first as plain text\n",
    "text = \"I am Sam. Sam I am. I do not like green eggs and ham.\"\n",
    "# ... and here it is cut up into sentences\n",
    "text_sents = nltk.sent_tokenize(text)\n",
    "# ... and cut up into words\n",
    "text_words = nltk.word_tokenize(text)\n",
    "# ... and cut up into sentences, each of which\n",
    "# is cut up into words\n",
    "text_sent_words = [ ]\n",
    "for s in text_sents:\n",
    "    text_sent_words.append(nltk.word_tokenize(s))\n",
    "    \n",
    "print(\"Corpus as a list of sentences:\", text_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3101d9b7",
   "metadata": {},
   "source": [
    "We add sentence beginning and end markers, so that we can also count how often a word appears in the beginning or end of a sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b34209a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<s>', 'I', 'am', 'Sam', '.', '</s>', '<s>', 'Sam', 'I', 'am', '.', '</s>', '<s>', 'I', 'do', 'not', 'like', 'green', 'eggs', 'and', 'ham', '.', '</s>']\n"
     ]
    }
   ],
   "source": [
    "# this is a corpus of consecutive words, not a corpus\n",
    "# of sentences\n",
    "sam_corpus = []\n",
    "for st in text_sent_words:\n",
    "    sam_corpus = sam_corpus + [\"<s>\"] + st + [\"</s>\"]\n",
    "    \n",
    "print(sam_corpus)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8f15c3",
   "metadata": {},
   "source": [
    "Now we make word pairs, and count. For this, we can use the function `nltk.bigrams()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6782962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('<s>', 'I'), ('I', 'am'), ('am', 'Sam'), ('Sam', '.'), ('.', '</s>'), ('</s>', '<s>'), ('<s>', 'Sam'), ('Sam', 'I'), ('I', 'am'), ('am', '.'), ('.', '</s>'), ('</s>', '<s>'), ('<s>', 'I'), ('I', 'do'), ('do', 'not'), ('not', 'like'), ('like', 'green'), ('green', 'eggs'), ('eggs', 'and'), ('and', 'ham'), ('ham', '.'), ('.', '</s>')]\n"
     ]
    }
   ],
   "source": [
    "sam_bigrams = list(nltk.bigrams(sam_corpus))\n",
    "\n",
    "print(sam_bigrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a46f54",
   "metadata": {},
   "source": [
    "# Counting words, and computing relative frequencies\n",
    "\n",
    "## Conditional Frequency Distribution objects in NLTK\n",
    "\n",
    "The Natural Language Toolkit has data types and functions that make life easier for us when we want to count word n-grams and compute their probabilities.\n",
    "\n",
    "A FreqDist object is a mapping from words (or word pairs) to counts. Here are the frequencies of all word pairs in the Sam corpus, sorted by frequency: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "719abea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". </s> \t 3\n",
      "<s> I \t 2\n",
      "I am \t 2\n",
      "</s> <s> \t 2\n",
      "am Sam \t 1\n",
      "Sam . \t 1\n",
      "<s> Sam \t 1\n",
      "Sam I \t 1\n",
      "am . \t 1\n",
      "I do \t 1\n",
      "do not \t 1\n",
      "not like \t 1\n",
      "like green \t 1\n",
      "green eggs \t 1\n",
      "eggs and \t 1\n",
      "and ham \t 1\n",
      "ham . \t 1\n"
     ]
    }
   ],
   "source": [
    "fd = nltk.FreqDist(sam_bigrams)\n",
    "for wordpair, count in fd.most_common(20):\n",
    "    print(wordpair[0], wordpair[1], \"\\t\", count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d32488",
   "metadata": {},
   "source": [
    "The ConditionalFreqDist object counts pairs of items, for example: Given that the first word in a pair is 'said', how often is the second word 'Alice'? How often is it 'the'?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "988a7ad0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'am': 2, 'do': 1})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This makes the object\n",
    "cfd = nltk.ConditionalFreqDist(sam_bigrams)\n",
    "# This looks up the counts of bigrams starting in \"I\"\n",
    "cfd[\"I\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510031a3",
   "metadata": {},
   "source": [
    "## Computing bigram probabilities \n",
    "\n",
    "As we have discussed in class, we can *estimate* the probability of, say, seeing the word \"am\" *given that* we have just seen \"I\", $P(am | I)$ using word counts: It is the number of times we have seen \"I am\", out of all the times we have seen \"I\" plus some following word. \n",
    "\n",
    "NLTK has a data structure that does this for us automatically: It converts a ConditionalFreqDist into probabilities. This data structure is, appropriately, called a ConditionalProbDist.\n",
    "\n",
    "We tell it that we want \"MLE\" probabilities, which stands for \"Maximum Likelihood Estimation\". This is exactly what we have been discussing, estimating probabilities as relative frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8ac780e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this makes the object\n",
    "cp = nltk.ConditionalProbDist(cfd, nltk.MLEProbDist)\n",
    "# this is p(am|I)\n",
    "cp[\"I\"].prob(\"am\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4559a907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words that can come after 'I':\n",
      " ['am', 'do']\n",
      "And here are their probabilities:\n",
      "am 0.6666666666666666\n",
      "do 0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "# Here are all the words that could follow \"I\"\n",
    "print(\"Words that can come after 'I':\\n\", list(cp[\"I\"].samples()))\n",
    "# For each word in samples(), we can get its probability\n",
    "# using prob()\n",
    "print(\"And here are their probabilities:\")\n",
    "for word in cp[\"I\"].samples():\n",
    "    print(word, cp[\"I\"].prob(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4447d520",
   "metadata": {},
   "source": [
    "# Generating text: In each step, choose the next word proportional to its frequency \n",
    "\n",
    "\n",
    "We can now use the Sam corpus to generate text. This is just like predictive typing. In the simplest case, we can always select the most frequent following word. For \"I\", this is \"am\". (When there are several words with equal frequency as a next word, we'll just pick the first one for simplicity.) Here is what this does:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f754644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> I am Sam . </s> <s> I am Sam . </s> <s> I am Sam . </s> <s> I am Sam . </s> <s> I am Sam . </s> <s> "
     ]
    }
   ],
   "source": [
    "currentword = \"<s>\"\n",
    "print(currentword, end = \" \")\n",
    "\n",
    "for i in range(30):\n",
    "    currentword = cp[currentword].max()\n",
    "    print(currentword, end = \" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366294aa",
   "metadata": {},
   "source": [
    "This is a bit repetitive. We can generate more interesting text by not always picking the single most likely next word, but choosing among the possible next words by their frequency of following our current word -- or rather, choosing the next word by its conditionalm probability given the previous word. \n",
    "\n",
    "The Python *scipy* package has an object that describes a multinomial distribution, called ```stats.multinomial```. It has a function called ```rvs()``` that we can use for this purpose: It will give us a probabilistic answer, a different one each time we run it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dda24414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the words are: ['am', 'do']\n",
      "with matching probabilities [0.6666666666666666, 0.3333333333333333]\n",
      "Note that they sum up to one.\n",
      "raw output of rvs: [1 0]\n",
      "we got this word: am\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "num_words_to_generate = 1\n",
    "# which words can follow \"I\"?\n",
    "words_following_i = list(cp[\"I\"].samples())\n",
    "# and what are their probabilities? \n",
    "outcome_probs = [cp[\"I\"].prob(word) for word in words_following_i]\n",
    "print(\"the words are:\", words_following_i)\n",
    "print(\"with matching probabilities\", outcome_probs)\n",
    "print(\"Note that they sum up to one.\")\n",
    "\n",
    "# let's get one sample\n",
    "outcome = stats.multinomial.rvs(num_words_to_generate, outcome_probs)\n",
    "print(\"raw output of rvs:\", outcome)\n",
    "\n",
    "# not so very readable. \n",
    "# this gives us, for each word that can follow \"I\", \n",
    "# how often it was sampled. \n",
    "# here is how we can make it readable:\n",
    "# at what position does this result have a \"1\"?\n",
    "# that's the word we sampled\n",
    "index_of_outcome = list(outcome).index(1)\n",
    "# The new current word is the word at that index\n",
    "sampled_word = words_following_i[ index_of_outcome]\n",
    "print(\"we got this word:\", sampled_word)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a66beaaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "am am am am am do do do do do am am am am am do do am am am "
     ]
    }
   ],
   "source": [
    "# let's do this a few times, to see what we get\n",
    "for i in range(20):\n",
    "    outcome = stats.multinomial.rvs(num_words_to_generate, outcome_probs)\n",
    "    index_of_outcome = list(outcome).index(1)\n",
    "    # The new current word is the word at that index\n",
    "    sampled_word = words_following_i[ index_of_outcome]\n",
    "    print(sampled_word, end = \" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6767198",
   "metadata": {},
   "source": [
    "Here is what `stats.multinomial` actually is:\n",
    "\n",
    "Say you roll one die. If it is a fair die, rhen each side has a probability of 1/6 of coming up. We can describe this with a *categorical distribution*.\n",
    "\n",
    "Now say you roll a loaded die. We can still describe this with a categorical distribution, the probabilities of all the sides are just not going to be the same.\n",
    "\n",
    "Now say we roll 20 dice that are all fair (or unfair) in the same way. How often will we get a 1? This can be described with a *multinomial distribution*.\n",
    "\n",
    "Here is a dice-rolling example. If you run this box several times, you should get a different result each time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86086f1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I just rolled one die. Here is what I got.\n",
      "Here is what the result looks like out of the box: [0 0 1 0 0 0]\n",
      "And here is how we can interpret this:\n",
      "I rolled a 3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# we have 6 possible outcomes, each with a probability of 1/6\n",
    "outcomes = [1,2,3,4,5,6]\n",
    "outcome_probs = [1/6, 1/6, 1/6, 1/6, 1/6, 1/6]\n",
    "# we only roll one die\n",
    "num_dice = 1\n",
    "\n",
    "result = stats.multinomial.rvs(num_dice, outcome_probs)\n",
    "print(\"I just rolled one die. Here is what I got.\")\n",
    "# the result we get is a list of 0's and 1's. We get a 1 for\n",
    "# the number that we rolled\n",
    "print(\"Here is what the result looks like out of the box:\", result)\n",
    "# the index of the outcome we got is the \n",
    "# place in the result that has a 1\n",
    "index_of_outcome = list(result).index(1)\n",
    "print(\"And here is how we can interpret this:\")\n",
    "print(\"I rolled a\", outcomes[index_of_outcome])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e27a90",
   "metadata": {},
   "source": [
    "Now we are ready to generate a longer stretch of text. We start with the sentence start symbol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea226514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> I do not like green eggs and ham . </s> <s> I do not like green eggs and ham . </s> <s> I am Sam I do not like green eggs and ham . </s> <s> Sam . </s> <s> Sam . </s> <s> Sam I am . </s> <s> "
     ]
    }
   ],
   "source": [
    "currentword = \"<s>\"\n",
    "print(currentword, end = \" \")\n",
    "# The language model knows, for each word w, \n",
    "# the conditional probability P(w|currentword).\n",
    "# We use that to generate text:\n",
    "# we start with the sentence-start symbol\n",
    "for i in range(50):\n",
    "    # get all the possible words that can follow the current word\n",
    "    outcomes = list(cp[currentword].samples())\n",
    "    # and get their probabilities\n",
    "    outcome_probs = [cp[currentword].prob(word) for word in outcomes]\n",
    "    # we only sample one next word\n",
    "    num_dice = 1\n",
    "    # sample the next word\n",
    "    result = stats.multinomial.rvs(num_dice, outcome_probs)\n",
    "    # which outcome index did we sample?\n",
    "    index_of_outcome = list(result).index(1)\n",
    "    # The new current word is the word at that index\n",
    "    currentword = outcomes[ index_of_outcome]\n",
    "    # print it, and repeat\n",
    "    print(currentword,end = \" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33426507",
   "metadata": {},
   "source": [
    "# Everything again, just much easier: NLTK's built-in language n-gram language model\n",
    "\n",
    "NLTK also has a built-in language model with which we can do the same thing more easily:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b1bff037",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's re-preprocess the Sam corpus, \n",
    "# to remind ourselves how we did it.\n",
    "# we import the natural language toolkit\n",
    "import nltk\n",
    "\n",
    "\n",
    "# Here is our corpus, first as plain text\n",
    "text = \"I am Sam. Sam I am. I do not like green eggs and ham.\"\n",
    "# ... and here it is cut up into sentences\n",
    "text_sents = nltk.sent_tokenize(text)\n",
    "# ... and cut up into words\n",
    "text_words = nltk.word_tokenize(text)\n",
    "# ... and cut up into sentences, each of which\n",
    "# is cut up into words\n",
    "text_sent_words = [ nltk.word_tokenize(s) for s in text_sents]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5915da",
   "metadata": {},
   "source": [
    "Instead of only using bigrams to come up with word sequences, we can also add single-word (unigram) counts, so that we also sometimes generate word sequences that haven't been seen exactly like that in the text. NLTK has a fun function \"everygrams\" that computes n-grams up to a given length:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb32da2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I',), ('I', 'am'), ('am',), ('am', 'Sam'), ('Sam',), ('Sam', '.'), ('.',)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(nltk.everygrams(text_sent_words[0], max_len  = 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c43357e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>', 'I', 'am', 'Sam', '.', '</s>']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NLTK has a functionality for helping us with \n",
    "# the sentence tags\n",
    "from nltk.lm.preprocessing import pad_both_ends\n",
    "# the parameter n=2 tells the function\n",
    "# that we're going to do bigrams eventually\n",
    "list(pad_both_ends(text_sent_words[0], n=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4d734570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('<s>',), ('<s>', 'I'), ('I',), ('I', 'am'), ('am',), ('am', 'Sam'), ('Sam',), ('Sam', '.'), ('.',), ('.', '</s>'), ('</s>',)], [('<s>',), ('<s>', 'Sam'), ('Sam',), ('Sam', 'I'), ('I',), ('I', 'am'), ('am',), ('am', '.'), ('.',), ('.', '</s>'), ('</s>',)], [('<s>',), ('<s>', 'I'), ('I',), ('I', 'do'), ('do',), ('do', 'not'), ('not',), ('not', 'like'), ('like',), ('like', 'green'), ('green',), ('green', 'eggs'), ('eggs',), ('eggs', 'and'), ('and',), ('and', 'ham'), ('ham',), ('ham', '.'), ('.',), ('.', '</s>'), ('</s>',)]]\n",
      "['<s>', 'I', 'am', 'Sam', '.', '</s>', '<s>', 'Sam', 'I', 'am', '.', '</s>', '<s>', 'I', 'do', 'not', 'like', 'green', 'eggs', 'and', 'ham', '.', '</s>']\n"
     ]
    }
   ],
   "source": [
    "# padding and making bigrams,\n",
    "# then combining everything into a \n",
    "# list of words \n",
    "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
    "sam_corpus_thing, vocabulary_thing = padded_everygram_pipeline(2, text_sent_words)\n",
    "\n",
    "# usually we don't turn this iterators\n",
    "# into lists, but let's do it here\n",
    "# to see what we've got\n",
    "sam_corpus = [list(s) for s in sam_corpus_thing]\n",
    "vocabulary = list(vocabulary_thing)\n",
    "\n",
    "print(sam_corpus)\n",
    "print(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ae3e5988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing, and building a language model\n",
    "sam_corpus, vocabulary = padded_everygram_pipeline(2, text_sent_words)\n",
    "\n",
    "# and its maximum likelihood estimation (MLE) language model\n",
    "from nltk.lm import MLE\n",
    "\n",
    "# lm is now an object of type MLE, in particular\n",
    "# a bigram language model, because we put the parameter 2\n",
    "lm_sam = MLE(2)\n",
    "\n",
    "lm_sam.fit(sam_corpus, vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2994eb",
   "metadata": {},
   "source": [
    "Now we can use this language model. Note that it also generates sentences starting with \"ham\" or \"green\", even though it has never seen that in the corpus. That is because of the mixed-in single-word counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d6183088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "</s> Sam . </s> . </s> . </s> <s> Sam . </s> am Sam I do not like green eggs and ham . </s> do not like green eggs and ham . </s> <s> Sam I do not like green eggs and ham . </s> green eggs and ham . "
     ]
    }
   ],
   "source": [
    "for word in lm_sam.generate(50):\n",
    "    print(word, end = \" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755b0b5c",
   "metadata": {},
   "source": [
    "## Getting more information out of the language model\n",
    "\n",
    "Here is how to look up the conditional probability of, say \"am\" given \"I\": "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "49dc7f0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_sam.score(\"am\", [ \"I\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00609310",
   "metadata": {},
   "source": [
    "And here is the probability (non-conditional) for a word, here \"am\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "88a25dfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08695652173913043"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_sam.score(\"am\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219bcf07",
   "metadata": {},
   "source": [
    "## Using a more interesting text\n",
    "\n",
    "Let's finally move away from the tiny \"Sam corpus\". Let's use Lewis Carroll's \"Alice in Wonderland\", available on Project Gutenberg here: http://www.gutenberg.org/ebooks/11 Please get the plain text version, and store it in the same directory as this notebook as a file 11-0.txt\n",
    "\n",
    "We read the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "760dafad",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"11-0.txt\")\n",
    "alice_text = f.read()\n",
    "f.close()\n",
    "\n",
    "import nltk\n",
    "\n",
    "alice_sents = nltk.sent_tokenize(alice_text)\n",
    "alice_sents_tokenized = [ nltk.word_tokenize(s) for s in alice_sents]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f7b7791c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing, which is now very simple,\n",
    "# and building the language model\n",
    "# let's do up to bigrams for now\n",
    "ngrams = 2\n",
    "\n",
    "alice_corpus, vocabulary = padded_everygram_pipeline(ngrams, alice_sents_tokenized)\n",
    "\n",
    "lm_alice = MLE(ngrams)\n",
    "\n",
    "lm_alice.fit(alice_corpus, vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5ce7d9c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "” said Alice could not uniform and feebly stretching out altogether , would be no use of sticks and washing ? ” said the Gryphon in it might not possibly make out in a little , it , as hard as she did not protected by wild beast , and "
     ]
    }
   ],
   "source": [
    "# and generating text\n",
    "for word in lm_alice.generate(50):\n",
    "    print(word, end = \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d3264126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how are things different if we do trigrams?\n",
    "ngrams = 3\n",
    "\n",
    "alice_corpus, vocabulary = padded_everygram_pipeline(ngrams, alice_sents_tokenized)\n",
    "\n",
    "lm_alice = MLE(ngrams)\n",
    "\n",
    "lm_alice.fit(alice_corpus, vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6429c778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "“ Are their heads . </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> "
     ]
    }
   ],
   "source": [
    "# and generating text\n",
    "for word in lm_alice.generate(50):\n",
    "    print(word, end = \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494c1177",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
